# Telecom Churn Contingency

## About
This is the mini project of Group 4 from Lab Group FCEE for SC1015 (Introduction to Data Science and Artificial Intelligence).


## Problem Definition
- TEST1
- TEST2
- TEST3 

## Dataset Used
The dataset used for this project is retrieved from [Kaggle](https://www.kaggle.com/datasets/vhcg77/telcom-churns-dataset).

## Presentation
The presentation video can be found [here](INSERT YOUR YOUTUBE LINK HERE).

## Brief Process Walkthrough 

1. **Data Preparation & Cleaning**
    - Data cleaning
      - Salvage empty rows with mean value
      - Drop empty rows after all cleaning steps (Dirty data)
      - Dropping of irrelevant columns
        
    - Data generation
      - Upsampling of the minority classes to ensure overall balance.

2. **Exploratory Data Analysis**
   - Class analysis
   - Word count & char count analysis
   - Author analysis
   - Corpus analysis
   - N-gram analysis
   - Sentiment & emotion analysis
   - Parts-of-speech (POS) analysis
   - Correlation analysis
  
3. **Model Training Attempt 1**
   - TF-IDF analysis 
   - Attempt 1 (Logistic Regression)
     - Average accuracy: 0.00
     - Model evaluation
       - Confusion Matrix
       - Recall, precision, F1 score
       - Receiver Operating Characteristic (ROC) Curve & Area Under Curve (AUC)
       - Model weights
      
4. **Model Training Attempt 2**
   - Attempt 2 (KNN Clustering)
     - Average accuracy: 0.00
     - Model evaluation
       - Confusion Matrix
       - Recall, precision, F1 score
       - Receiver Operating Characteristic (ROC) Curve & Area Under Curve (AUC)
       - Model weights
      
5. **Model Training Attempt 3**
   - Attempt 1 (Decision Tree)
     - Train with top 5 predictors
     - Average accuracy: 0.00
     - Model evaluation
       - Plotting decision tree
       - Confusion matrix
        
6. **Model Training Attempt 4**
   - Attempt 2 (Random Forest)
     - Train with top 5 predictors
     - Average accuracy: 0.00
     - Model evaluation
       - Confusion matrix
       - Grid search hyper-parameter tuning
      
## Remodelling with Upsampled Data
3. **ReModel Training Attempt 1 with Upsampled Data**
   - TF-IDF analysis 
   - Attempt 1 (Logistic Regression)
     - Average accuracy: 0.00
     - Model evaluation
       - Confusion Matrix
       - Recall, precision, F1 score
       - Receiver Operating Characteristic (ROC) Curve & Area Under Curve (AUC)
       - Model weights
      
4. **ReModel Training Attempt 2**
   - Attempt 2 (KNN Clustering)
     - Average accuracy: 0.00
     - Model evaluation
       - Confusion Matrix
       - Recall, precision, F1 score
       - Receiver Operating Characteristic (ROC) Curve & Area Under Curve (AUC)
       - Model weights
      
5. **ReModel Training Attempt 3**
   - Attempt 1 (Decision Tree)
     - Train with top 5 predictors
     - Average accuracy: 0.00
     - Model evaluation
       - Plotting decision tree
       - Confusion matrix
        
6. **ReModel Training Attempt 4**
   - Attempt 2 (Random Forest)
     - Train with top 5 predictors
     - Average accuracy: 0.00
     - Model evaluation
       - Confusion matrix
       - Grid search hyper-parameter tuning

## Conclusion
- Testing

## Key Learning Points
- Different modeling methods (KNN, Logistic Regression, Random Forest)
  - KNN clustering
  - Logistic Regression
  - Random Forest
- Logistic regression model training & evaluation
- Optimization of specifications for tuning of hyperparameters for random forest
- Resampling of dataset to ensure a balanced view of the dataset.

## Contributors

1. [@zchua040](https://github.com/zchua040) (Chua Zhi Li) - Data Preparation & Cleaning, Exploratory Data Analysis, Presentation Slides, Model Training Attempt 1 and 2
2. [@chaaitra001](https://github.com/chaaitra001) (Guda Chaaitra Joseph) - Model Training Attempt 3, Presentation Slides, Presenter
3. [@qchong005](https://github.com/qchong005) (Chong Qi En) - Model Training Attempt 4, Presentation Slides, Presenter

## References
- List any references here.

